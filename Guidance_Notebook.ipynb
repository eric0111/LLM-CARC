{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf18bad-09c8-422a-b272-d77d74907f10",
   "metadata": {},
   "source": [
    "#### Info\n",
    "Microsoft Guidance has been quite challenging to work with (https://github.com/guidance-ai/guidance). Here are the steps I had to take:\n",
    "- I created a custom function that divides the CSV file into multiple chunks, each containing a maximum of 1000 rows\n",
    "- I added a call to the garbage collector and emptied the cache to free up memory, as Guidance wasn't releasing it properly. However, this wasn't sufficient...\n",
    "- To further enforce memory release, I had to resort to using Python's multiprocessing\n",
    "- If the system crashes for any reason, or if the job exceeds the allocated time, you can restart it, and the system will resume from where it left off\n",
    "- The results will be displayed in a file named output.txt located in the generated folder\n",
    "- An estimate of the total time required to complete the entire run is provided, based on the duration of the last run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd7de1-81af-4d85-8168-83cdfea7a65e",
   "metadata": {},
   "source": [
    "#### Guide\n",
    "- Go to https://ondemand.carc.usc.edu/pun/sys/dashboard/batch_connect/sys/jupyter/session_contexts/new to start a new jupyterlab interactive session\n",
    "- Fill out using the following JupyterLab Parameters\n",
    "- Generate a JSON file using the following json file example\n",
    "- Update the parameters\n",
    "- Run the code blocks to load the functions and execute them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10736811-6d45-4db8-91b5-7384aafa3d27",
   "metadata": {},
   "source": [
    "#### JupyterLab Parameters\n",
    "1. **Cluster**: Discovery.\n",
    "2. **JupyterLab Version**: Set the version to `4.0.5`.\n",
    "3. **Working Directory (optional)**: Leave empty.\n",
    "4. **Modules to Load (optional)**: Set this fied to `gcc/11.3.0 python/3.9.12 git/2.36.1 nvidia-hpc-sdk cuda/11.8.0`.\n",
    "5. **Account**: Set this field to `ll_774_951` or the account of your PI.\n",
    "6. **Partition**: Set the partition to `gpu`.\n",
    "7. **Number of CPUs**: Set the number of CPU cores to `16`.\n",
    "8. **Memory (GB)**: Set the allocated memory to `128 GB`.\n",
    "9. **GPU Type (optional)**: Set the GPU type to `a40` or `a100`.\n",
    "10. **Number of Hours**: Set the duration of the session to `8 hours`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634a421-e187-47db-b710-c5d54f897b98",
   "metadata": {},
   "source": [
    "#### Json File Example: tweets.json\n",
    "[{\"instruction\": \"Determine if the following tweet is part of an influence campaign.\", \"input\": \"@LoboCarnicero6 @mariannaramosc s\\u00ed, pero al menos algunos protestamos para que todos tengamos comida y no nos sentamos a aplaudir a las basuras que nos tienen tan mal\", \"output\": \"False\"}, {\"instruction\": \"Determine if the following tweet is part of an influence campaign.\", \"input\": \"@LoboCarnicero6 @mariannaramosc \\u00bfy cu\\u00e0l es la mentira seg\\u00fan t\\u00fa? \\u00bfla represi\\u00f3n desmedida? los que estuvimos ah\\u00ed sabemos que es as\\u00ed.\", \"output\": \"False\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8215bb42-098e-44c6-be45-4387fe74046f",
   "metadata": {},
   "source": [
    "#### Update with your parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45d0fe3-1bfe-44e9-a1fb-ec5cdc0a91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filepath = '/scratch1/ashwinba/Untitled Folder/test_mee_tweets_ecuador.json'\n",
    "directory = '/scratch1/ashwinba/Untitled Folder' #directory where the notebook is located\n",
    "model = \"meta-llama/Llama-2-7b-hf\" #huggingface model\n",
    "temperature = 0.01 #the lower the more deterministic\n",
    "prompt = '''Determine if the following tweet is part of an influence campaign. Please answer with a single word, either \"True\" or \"False\".\n",
    "    Tweet: {{tweet_text}}\n",
    "    Answer:{{#select \"answer\" logprobs='logprobs'}} True{{or}} False{{/select}}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2037f371-ec5b-4e86-8e7f-01833504f9a9",
   "metadata": {},
   "source": [
    "#### Install packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824f9fec-83dd-4251-8080-0f7124b856cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: regex in /home1/ashwinba/.local/lib/python3.11/site-packages (2023.10.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: guidance in /home1/ashwinba/.local/lib/python3.11/site-packages (0.0.64)\n",
      "Requirement already satisfied: diskcache in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (5.6.3)\n",
      "Requirement already satisfied: gptcache in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (0.1.42)\n",
      "Requirement already satisfied: openai>=0.27.8 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.3.3)\n",
      "Requirement already satisfied: pyparsing>=3.0.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (3.1.1)\n",
      "Requirement already satisfied: pygtrie in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (2.5.0)\n",
      "Requirement already satisfied: platformdirs in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (3.10.0)\n",
      "Requirement already satisfied: tiktoken>=0.3 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (0.5.1)\n",
      "Requirement already satisfied: nest-asyncio in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (1.5.6)\n",
      "Requirement already satisfied: msal in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.25.0)\n",
      "Requirement already satisfied: requests in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (2.31.0)\n",
      "Requirement already satisfied: numpy in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.26.0)\n",
      "Requirement already satisfied: aiohttp in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (3.9.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (2.5.1)\n",
      "Requirement already satisfied: tqdm>4 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (4.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home1/ashwinba/.local/lib/python3.11/site-packages (from tiktoken>=0.3->guidance) (2023.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from aiohttp->guidance) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.3.1)\n",
      "Requirement already satisfied: cachetools in /home1/ashwinba/.local/lib/python3.11/site-packages (from gptcache->guidance) (5.3.2)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from msal->guidance) (2.8.0)\n",
      "Requirement already satisfied: cryptography<44,>=0.6 in /home1/ashwinba/.local/lib/python3.11/site-packages (from msal->guidance) (41.0.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai>=0.27.8->guidance) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from cryptography<44,>=0.6->msal->guidance) (1.15.1)\n",
      "Requirement already satisfied: httpcore in /home1/ashwinba/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=0.27.8->guidance) (1.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->guidance) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->guidance) (2.14.3)\n",
      "Requirement already satisfied: pycparser in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44,>=0.6->msal->guidance) (2.21)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home1/ashwinba/.local/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai>=0.27.8->guidance) (0.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==2.1.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pandas==2.1.0) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from pandas==2.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from pandas==2.1.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pandas==2.1.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.1.0) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: guidance in /home1/ashwinba/.local/lib/python3.11/site-packages (0.0.64)\n",
      "Requirement already satisfied: diskcache in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (5.6.3)\n",
      "Requirement already satisfied: gptcache in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (0.1.42)\n",
      "Requirement already satisfied: openai>=0.27.8 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.3.3)\n",
      "Requirement already satisfied: pyparsing>=3.0.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (3.1.1)\n",
      "Requirement already satisfied: pygtrie in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (2.5.0)\n",
      "Requirement already satisfied: platformdirs in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (3.10.0)\n",
      "Requirement already satisfied: tiktoken>=0.3 in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (0.5.1)\n",
      "Requirement already satisfied: nest-asyncio in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (1.5.6)\n",
      "Requirement already satisfied: msal in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.25.0)\n",
      "Requirement already satisfied: requests in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from guidance) (2.31.0)\n",
      "Requirement already satisfied: numpy in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (1.26.0)\n",
      "Requirement already satisfied: aiohttp in /home1/ashwinba/.local/lib/python3.11/site-packages (from guidance) (3.9.0)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (2.5.1)\n",
      "Requirement already satisfied: tqdm>4 in /home1/ashwinba/.local/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from openai>=0.27.8->guidance) (4.7.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home1/ashwinba/.local/lib/python3.11/site-packages (from tiktoken>=0.3->guidance) (2023.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->guidance) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from aiohttp->guidance) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home1/ashwinba/.local/lib/python3.11/site-packages (from aiohttp->guidance) (1.3.1)\n",
      "Requirement already satisfied: cachetools in /home1/ashwinba/.local/lib/python3.11/site-packages (from gptcache->guidance) (5.3.2)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from msal->guidance) (2.8.0)\n",
      "Requirement already satisfied: cryptography<44,>=0.6 in /home1/ashwinba/.local/lib/python3.11/site-packages (from msal->guidance) (41.0.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai>=0.27.8->guidance) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from cryptography<44,>=0.6->msal->guidance) (1.15.1)\n",
      "Requirement already satisfied: httpcore in /home1/ashwinba/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=0.27.8->guidance) (1.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->guidance) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home1/ashwinba/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=0.27.8->guidance) (2.14.3)\n",
      "Requirement already satisfied: pycparser in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from cffi>=1.12->cryptography<44,>=0.6->msal->guidance) (2.21)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home1/ashwinba/.local/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai>=0.27.8->guidance) (0.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyparsing in /home1/ashwinba/.local/lib/python3.11/site-packages (3.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: regex in /home1/ashwinba/.local/lib/python3.11/site-packages (2023.10.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: glob2 in /home1/ashwinba/.local/lib/python3.11/site-packages (0.7)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home1/ashwinba/.local/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home1/ashwinba/.local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home1/ashwinba/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home1/ashwinba/.local/lib/python3.11/site-packages (from torch==2.0.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from torch==2.0.1) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home1/ashwinba/.local/lib/python3.11/site-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home1/ashwinba/.local/lib/python3.11/site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from torch==2.0.1) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (68.1.2)\n",
      "Requirement already satisfied: wheel in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.41.1)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/5a/e1/001da8b79b5d336d42aee95aae4cb934348ffa8925a6280fcd81859d8734/cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
      "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /spack/conda/envs/ood-jupyterlab-v4/lib/python3.11/site-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home1/ashwinba/.local/lib/python3.11/site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading cmake-3.27.7-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=34767d1070eb5fe6b50e0c3994b1dbaba83a2e8b6a94689844c9fe150bf102ce\n",
      "  Stored in directory: /home1/ashwinba/.cache/pip/wheels/a1/26/a4/40c6cd80874b94237593690352a2f657f5e4d7bddf6de4a6cd\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.1\n",
      "    Uninstalling torch-2.1.1:\n",
      "      Successfully uninstalled torch-2.1.1\n",
      "Successfully installed cmake-3.27.7 lit-17.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install regex\n",
    "!{sys.executable} -m pip install guidance \n",
    "!{sys.executable} -m pip install pandas==2.1.0\n",
    "!{sys.executable} -m pip install guidance\n",
    "!{sys.executable} -m pip install pyparsing\n",
    "!{sys.executable} -m pip install regex\n",
    "!{sys.executable} -m pip install glob2\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15fa41c-b083-4661-84af-e46be21abd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to install package: redis\n",
      "successfully installed package: redis\n",
      "start to install package: redis-om\n",
      "successfully installed package: redis-om\n"
     ]
    }
   ],
   "source": [
    "#Import modules\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import math\n",
    "import guidance\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ec635-8382-40ee-b3bb-d16803b0fb0a",
   "metadata": {},
   "source": [
    "#### Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcf66ee-5650-4e10-aa81-a494daa2555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads a JSON file, divides it into chunks of a specified size, writes each chunk to a new JSON file in a specified directory, \n",
    "#and returns a list of the file paths of the new JSON files\n",
    "\n",
    "def divide_json(file_name, output_dir):\n",
    "    chunk_size = 1000\n",
    "    batch_no = 1\n",
    "\n",
    "    # Get the base file name without the .json extension\n",
    "    base_name = os.path.basename(file_name).replace('.json', '')\n",
    "    \n",
    "    # Create a new directory for the chunks\n",
    "    dir_name = output_dir + '/' + base_name\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "    # List to store the names of all generated files\n",
    "    file_list = []\n",
    "\n",
    "    # Read the entire JSON file\n",
    "    df = pd.read_json(file_name)\n",
    "\n",
    "    # Drop the empty rows\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    # Divide the DataFrame into chunks\n",
    "    chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        new_file_name = dir_name + '/' + base_name + str(batch_no) + '.json'\n",
    "        chunk.to_json(new_file_name, orient='records')\n",
    "        file_list.append(new_file_name)\n",
    "        batch_no += 1\n",
    "\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc4bd16-95f4-41a4-aea5-2f6fc675b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function `process_input_text` processes a given text, calls a function `structure_program` on it, and tries to extract an 'answer'\n",
    "#from the output. If it doesn't find an 'answer', it retries until it does, while managing memory during this process.\n",
    "\n",
    "def process_input_text(tweet_text, i, start_time, total, structure_program):\n",
    "    print(i)\n",
    "    answer = None\n",
    "    while answer is None:\n",
    "        out = structure_program(tweet_text=tweet_text)\n",
    "        try:\n",
    "            answer = out['answer']\n",
    "        except KeyError:\n",
    "            print(\"Key 'answer' not found in the output. Retrying...\")\n",
    "            print(out.variables())\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432c2a4d-a060-43c1-9f60-211c2e8def9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function `run_code` processes a given text using a transformer model, extracts 'answers' from the output, \n",
    "#and writes them into an output file.\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def run_code(filepath,model, prompt, temp):\n",
    "    # Check if the output file already exists\n",
    "    output_filepath = filepath.replace('.json', '_processed.json')\n",
    "    if os.path.exists(output_filepath):\n",
    "        print(f\"Output file {output_filepath} already exists. Skipping...\")\n",
    "        return\n",
    "\n",
    "    guidance.llm = guidance.llms.Transformers(model, device=device, temperature=temp)\n",
    "    structure_program = guidance(prompt)\n",
    "    df = pd.read_json(filepath)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i, t in enumerate(df['input']):\n",
    "        df.loc[i, 'answer'] = process_input_text(t, i, start_time, len(df),structure_program)\n",
    "        df.to_json(output_filepath, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f8cea-670f-4921-a346-b39d8fb7da8c",
   "metadata": {},
   "source": [
    "#### Run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e4ab9d-9d62-4fb4-94a4-37829599c9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 10:00:07,820 - 139747151476544 - 890038755.py-890038755:9 - INFO: Hello, world!\n"
     ]
    }
   ],
   "source": [
    "# Create loggers\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.FileHandler('result.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.info('Hello, world!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a74e1e2-4633-44cc-a535-1232809947b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd9099-3b7c-4b18-80e1-63ad0816e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-b2328efd-1fbf-441b-b2d5-00c70d04073b\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-b2328efd-1fbf-441b-b2d5-00c70d04073b\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>Determine if the following tweet is part of an influence campaign. Please answer with a single word, either &quot;True&quot; or &quot;False&quot;.\n",
       "    Tweet: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{tweet_text}}'>RT @JulianFMartinez: El senador uribista @AlfredoRamosM esperó que se apagara el micrófono para gritarle, en medio de la plenaria, “hija de…</span>\n",
       "    Answer:<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{#select &quot;answer&quot; logprobs=&#x27;logprobs&#x27;}} True{{or}} False{{/select}}'> True False True</span></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"b2328efd-1fbf-441b-b2d5-00c70d04073b\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n"
     ]
    }
   ],
   "source": [
    "#Run the main script\n",
    "file_list = divide_json(json_filepath, directory)\n",
    "processes = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, filepath in enumerate(file_list):\n",
    "    start_time = time.time()\n",
    "    p = multiprocessing.Process(target=run_code, args=(filepath, model, prompt, temperature))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "    # wait for the current process to finish before starting the next one\n",
    "    p.join()\n",
    "\n",
    "    # Log the estimated remaining time at the file level\n",
    "    elapsed_time = time.time() - start_time\n",
    "    remaining_files = len(file_list) - i - 1\n",
    "    remaining_time_minutes = round(elapsed_time * remaining_files / 60, 2)\n",
    "    logger.info(f'Tempo stimato rimanente: {remaining_time_minutes} minuti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f29c57b-9645-46c1-b789-dd45724e00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch1/ashwinba/Untitled Folder/test_mee_tweets_ecuador\n",
      "                                         instruction  \\\n",
      "0  Determine if the following tweet is part of an...   \n",
      "1  Determine if the following tweet is part of an...   \n",
      "2  Determine if the following tweet is part of an...   \n",
      "3  Determine if the following tweet is part of an...   \n",
      "4  Determine if the following tweet is part of an...   \n",
      "\n",
      "                                               input output  answer  \n",
      "0  RT @fanderfalconi: América Latina perdió una d...  False   False  \n",
      "1  RT @teleSURimpactoe: Bajo crecimiento económic...  False   False  \n",
      "2  RT @PolEconomicaEc: \"La cuota será cada vez me...  False   False  \n",
      "3  RT @ElCiudadano_ec: Presidente #Correa realizó...  False   False  \n",
      "4  RT @emaciastovar: Un nuevo ultimátum de Santos...  False    True  \n"
     ]
    }
   ],
   "source": [
    "# Generate Results:\n",
    "base_name = os.path.basename(json_filepath).replace('.json', '')\n",
    "\n",
    "# Create the directory path for the chunks\n",
    "dir_name = directory + '/' + base_name\n",
    "print(dir_name)\n",
    "\n",
    "# Get the list of all processed JSON files\n",
    "file_list = glob.glob(dir_name + \"/*_processed.json\")\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Load all JSON files into a single DataFrame\n",
    "for file in file_list:\n",
    "    df_temp = pd.read_json(file)\n",
    "    df = pd.concat([df, df_temp])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Ensure 'control' and 'answer' are booleans\n",
    "df['label'] = df['output'].apply(lambda x: True if str(x).strip() == 'True' else False)\n",
    "df['predict'] = df['answer'].apply(lambda x: True if str(x).strip() == 'True' else False)\n",
    "\n",
    "# Calculate classification metrics\n",
    "y_true = df['label']\n",
    "y_pred = df['predict']\n",
    "\n",
    "try:\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    # Calculate precision, recall, F1 score and AUC\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    with open(f'{dir_name}/output.txt', 'w') as f:\n",
    "        f.write(f'True Positives (TP): {tp}\\n')\n",
    "        f.write(f'False Positives (FP): {fp}\\n')\n",
    "        f.write(f'True Negatives (TN): {tn}\\n')\n",
    "        f.write(f'False Negatives (FN): {fn}\\n')\n",
    "\n",
    "        f.write(f'Precision: {precision}\\n')\n",
    "        f.write(f'Recall: {recall}\\n')\n",
    "        f.write(f'F1 Score: {f1}\\n')\n",
    "        f.write(f'AUC: {auc}\\n')\n",
    "        ll = [precision, recall, f1, auc]\n",
    "        f.write(f'{ll}\\n')\n",
    "        \n",
    "        # Print value counts\n",
    "        f.write('\\nValue counts:\\n')\n",
    "        f.write(str(df['output'].value_counts()) + '\\n')\n",
    "        f.write(str(df['answer'].value_counts()) + '\\n')\n",
    "        f.write(str(df['label'].value_counts()) + '\\n')\n",
    "        f.write(str(df['predict'].value_counts()) + '\\n')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while calculating classification metrics: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
